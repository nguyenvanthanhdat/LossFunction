{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"presencesw/vinli_3_label\"\n",
    "label = 'contradiction'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['gold_label', 'sentence1', 'sentence2'],\n",
      "        num_rows: 18282\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['gold_label', 'sentence1', 'sentence2'],\n",
      "        num_rows: 2264\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['gold_label', 'sentence1', 'sentence2'],\n",
      "        num_rows: 2255\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_entailment(exmaples):\n",
    "    labels = exmaples['gold_label']\n",
    "    labels = [f\"not_{label}\" if i != label else label for i in labels]\n",
    "    exmaples['gold_label'] = labels\n",
    "    return exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['gold_label', 'sentence1', 'sentence2'],\n",
       "    num_rows: 18282\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this step convert dataset to 2 labels\n",
    "converted_dataset = dataset.map(convert_entailment, batched=True)\n",
    "\n",
    "# check number samples in dataset train\n",
    "converted_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5c7b2120cc4f53aa87f2215b9c8b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/18282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f6b50203204c838ed60c9d1b09d280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b77fc5660ce4ef08db406ca56101e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff6b88eacb7494a945f7c661f46aa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/18282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648b80d2442a48ada9062d789d0da032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d540c6eb09dd434b8625f91faa1845c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Divine the dataset to 2 sets `entailment` and `not entailment`\n",
    "new_dataset_entail = converted_dataset.filter(lambda example: example['gold_label'] == label)['train']\n",
    "new_dataset_not_entail = converted_dataset.filter(lambda example: example['gold_label'] == f'not_{label}')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset to pandas for next step\n",
    "new_dataset_entail = Dataset.to_pandas(new_dataset_entail)\n",
    "# duplicate dataset not entailment\n",
    "new_dataset_not_entail1 = Dataset.to_pandas(new_dataset_not_entail)\n",
    "new_dataset_not_entail2 = Dataset.to_pandas(new_dataset_not_entail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12188/12188 [00:01<00:00, 6472.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# merge 2 dataset not entailment for the target\n",
    "j = 0\n",
    "for i in tqdm(range(len(new_dataset_not_entail1))):\n",
    "    temp = set()\n",
    "    # check = False\n",
    "    # for j in range(len(new_dataset_not_entail2)):\n",
    "    for index in range(100):\n",
    "        new_j = j + index\n",
    "        if new_j == len(new_dataset_not_entail1):\n",
    "            j = new_j\n",
    "            break\n",
    "        if new_dataset_not_entail1.iloc[i]['sentence1'] != new_dataset_not_entail2.iloc[new_j]['sentence1']:\n",
    "            j = new_j\n",
    "            break\n",
    "        temp.add(new_dataset_not_entail2.iloc[new_j]['sentence2'])\n",
    "    # new_dataset_not_entail1.iloc[i]['sentence2'] = temp\n",
    "    # temp = [val for val in temp]\n",
    "    new_dataset_not_entail1.at[i, 'sentence2'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3044\n"
     ]
    }
   ],
   "source": [
    "# dataset_not_entail = new_dataset_not_entail1.drop_duplicates(subset=['sentence2'])\n",
    "# print(len(dataset_not_entail))\n",
    "dataset_not_entail = new_dataset_not_entail1[new_dataset_not_entail1['sentence2'] != set()]\n",
    "print(len(dataset_not_entail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Sau dự án điện mặt trời, Tập đoàn Trung Nam vừ...</td>\n",
       "      <td>{Tập đoàn Trung Nam có ý định bán toàn bộ cổ p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Phía Tập đoàn Trung Nam cho biết, với 64,9% cổ...</td>\n",
       "      <td>{Nhiều người mong muốn được giữ quyền điều hàn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Cách đây một tháng, tập đoàn này cũng bán 49% ...</td>\n",
       "      <td>{Số cổ phần của tập đoàn Trung Nam tại Nhà máy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Dự án Nhà máy Điện gió Trung Nam, tổng số vốn ...</td>\n",
       "      <td>{Vốn đầu tư của Nhà máy Điện gió Trung Nam sẽ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Từ nay tới năm 2028, dòng vốn đầu tư được dự b...</td>\n",
       "      <td>{Những hoạt động đi lại còn hạn chế là do dịch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Ổ SSD dùng để khai thác tiền số Chia chỉ còn t...</td>\n",
       "      <td>{Việc khai thác tiền số Chia đã làm giảm tuổi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Khi khai thác Chia, những ổ cứng dung lượng lớ...</td>\n",
       "      <td>{Một ổ cứng sử dụng với mục đích thông thường ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Ổ cứng thường được hãng bảo hành từ ba đến năm...</td>\n",
       "      <td>{Người mua ổ cứng sẽ được bảo hành miễn phí từ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3042</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Ổ SSD được \"thợ đào\" Chia yêu thích vì tốc độ ...</td>\n",
       "      <td>{Ổ SSD có tốc độ xử lý cao hơn ổ HDD., Nhiều n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>not_contradiction</td>\n",
       "      <td>Chia là tiền điện tử đang \"sốt\" tại Trung Quốc.</td>\n",
       "      <td>{Cơn \"sốt\" mang tên tiền ảo Chia đã kéo dài đư...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3044 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gold_label                                          sentence1  \\\n",
       "0     not_contradiction  Sau dự án điện mặt trời, Tập đoàn Trung Nam vừ...   \n",
       "1     not_contradiction  Phía Tập đoàn Trung Nam cho biết, với 64,9% cổ...   \n",
       "2     not_contradiction  Cách đây một tháng, tập đoàn này cũng bán 49% ...   \n",
       "3     not_contradiction  Dự án Nhà máy Điện gió Trung Nam, tổng số vốn ...   \n",
       "4     not_contradiction  Từ nay tới năm 2028, dòng vốn đầu tư được dự b...   \n",
       "...                 ...                                                ...   \n",
       "3039  not_contradiction  Ổ SSD dùng để khai thác tiền số Chia chỉ còn t...   \n",
       "3040  not_contradiction  Khi khai thác Chia, những ổ cứng dung lượng lớ...   \n",
       "3041  not_contradiction  Ổ cứng thường được hãng bảo hành từ ba đến năm...   \n",
       "3042  not_contradiction  Ổ SSD được \"thợ đào\" Chia yêu thích vì tốc độ ...   \n",
       "3043  not_contradiction    Chia là tiền điện tử đang \"sốt\" tại Trung Quốc.   \n",
       "\n",
       "                                              sentence2  \n",
       "0     {Tập đoàn Trung Nam có ý định bán toàn bộ cổ p...  \n",
       "1     {Nhiều người mong muốn được giữ quyền điều hàn...  \n",
       "2     {Số cổ phần của tập đoàn Trung Nam tại Nhà máy...  \n",
       "3     {Vốn đầu tư của Nhà máy Điện gió Trung Nam sẽ ...  \n",
       "4     {Những hoạt động đi lại còn hạn chế là do dịch...  \n",
       "...                                                 ...  \n",
       "3039  {Việc khai thác tiền số Chia đã làm giảm tuổi ...  \n",
       "3040  {Một ổ cứng sử dụng với mục đích thông thường ...  \n",
       "3041  {Người mua ổ cứng sẽ được bảo hành miễn phí từ...  \n",
       "3042  {Ổ SSD có tốc độ xử lý cao hơn ổ HDD., Nhiều n...  \n",
       "3043  {Cơn \"sốt\" mang tên tiền ảo Chia đã kéo dài đư...  \n",
       "\n",
       "[3044 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_not_entail = dataset_not_entail.reset_index(drop=True)\n",
    "dataset_not_entail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6094/6094 [04:56<00:00, 20.56it/s]\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for index1 in tqdm(range(len(new_dataset_entail))):\n",
    "    # print(new_dataset_entail.iloc[index1]['sentence1'])\n",
    "    for index2 in range(len(dataset_not_entail)):\n",
    "        if new_dataset_entail.iloc[index1]['sentence1'] == dataset_not_entail.iloc[index2]['sentence1']:\n",
    "            temp.append(dataset_not_entail.iloc[index2]['sentence2'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6094\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_entail['negative'] = temp\n",
    "# new_dataset_entail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['gold_label', 'anchor', 'positive', 'negative'],\n",
       "    num_rows: 6094\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = Dataset.from_pandas(new_dataset_entail)\n",
    "new_dataset = new_dataset.rename_column(\"sentence1\", \"anchor\")\n",
    "new_dataset = new_dataset.rename_column(\"sentence2\", \"positive\")\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8197fe8a2564445e97cb4a8b2784356e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6094 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_dataset(example):\n",
    "    # print(example['negative'])\n",
    "    number = len(example['negative'][0])\n",
    "    # print(gold_label)\n",
    "    gold_label = example['gold_label'] * number\n",
    "    anchor = example['anchor'] * number\n",
    "    positive = example['positive'] * number\n",
    "    return {'gold_label': gold_label, 'anchor': anchor, \n",
    "            'positive': positive, 'negative': example['negative'][0]}\n",
    "\n",
    "        \n",
    "new_dataset = new_dataset.map(\n",
    "    lambda example: convert_dataset(example),                   \n",
    "    remove_columns=['gold_label', 'anchor', 'positive', 'negative'],\n",
    "    batched=True,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['gold_label', 'anchor', 'positive', 'negative'],\n",
       "    num_rows: 24406\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(['']*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(examples):\n",
    "    # print(len(examples))\n",
    "    length = len(examples['gold_label'])\n",
    "    examples['negative'] = [''] * length\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dataset = converted_dataset.rename_column(\"sentence1\", \"anchor\")\n",
    "converted_dataset = converted_dataset.rename_column(\"sentence2\", \"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baadf1414924964ba6df2e8fb0fcc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18282 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407d6170ccd44128844737c27c556d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2264 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d1cb1f020c403caa1ed48ca37df53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "converted_dataset = converted_dataset.map(add_columns, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = DatasetDict()\n",
    "all_data['train'] = new_dataset\n",
    "all_data['validation'] = converted_dataset['dev']\n",
    "all_data['test'] = converted_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bcee439d2144d684078fc38b6f9b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cd084df3f140e4849f6f6a30d86f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e314c517f3a347eda9506fab354ebaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a1545e132646f48b60b86c51a450f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8d381042e941cfac7e614f1b4659fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690f8165f6734aae9b4af0c2049e5b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddaf2e6372d34ffb9f2c02569c4c4df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/392 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/presencesw/vinli_3_label_contradiction/commit/fc48d832b9910ad0e5f7d8464c60781e97b6204b', commit_message='Upload dataset', commit_description='', oid='fc48d832b9910ad0e5f7d8464c60781e97b6204b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.push_to_hub(f\"{dataset_name}_{label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
